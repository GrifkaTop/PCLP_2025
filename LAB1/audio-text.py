import torch
import whisper
import os
import glob
import time
from pydub import AudioSegment
from pydub.utils import make_chunks

print("=" * 70)
print("üéØ –ê–£–î–ò–û -> –¢–ï–ö–°–¢ + –ü–†–û–ú–ü–¢ –î–õ–Ø –ö–û–ù–°–ü–ï–ö–¢–ò–†–û–í–ê–ù–ò–Ø")
print("=" * 70)

# –ó–∞—Å–µ–∫–∞–µ–º –æ–±—â–µ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã
total_start_time = time.time()

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

# –ü–∞–ø–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞
script_dir = os.path.dirname(os.path.abspath(__file__))
os.chdir(script_dir)
print(f"–ü–∞–ø–∫–∞: {script_dir}")

# –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5 - large)
print("\nü§ñ –í–´–ë–û–† –ú–û–î–ï–õ–ò WHISPER:")
print("1. tiny (—Å–ª–∞–±–∞—è) - –±—ã—Å—Ç—Ä–∞—è, –Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ")
print("2. base (–Ω–æ—Ä–º–∞–ª—å–Ω–∞—è) - –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏/–∫–∞—á–µ—Å—Ç–≤–∞") 
print("3. small (—Ö–æ—Ä–æ—à–∞—è) - —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, —É–º–µ—Ä–µ–Ω–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å")
print("4. medium (–æ—Ç–ª–∏—á–Ω–∞—è) - –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –º–µ–¥–ª–µ–Ω–Ω–∞—è")
print("5. large (–ª—É—á—à–∞—è) - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–∞—è")

model_choice = input("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å (1-5, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5): ").strip() or "5"

model_map = {
    "1": "tiny",
    "2": "base", 
    "3": "small",
    "4": "medium",
    "5": "large"
}

selected_model = model_map.get(model_choice, "large")
print(f"‚úÖ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {selected_model}")

# –í—ã–±–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1 - –≤–∫–ª—é—á–µ–Ω)
print("\nüîÑ –í–´–ë–û–† –ö–û–ù–¢–ï–ö–°–¢–ê:")
print("0. –ë–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ - –∫–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ")
print("1. –° –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º - —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ç–µ–∫—Å—Ç (–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)")

context_choice = input("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º (0-1, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1): ").strip() or "1"
use_context = context_choice != "0"
print(f"‚úÖ –†–µ–∂–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {'–í–ö–õ' if use_context else '–í–´–ö–õ'}")

# –ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤
audio_extensions = ['*.m4a', '*.mp3', '*.wav', '*.mp4', '*.ogg', '*.flac', '*.aac', '*.m4b']
audio_files = []

for ext in audio_extensions:
    audio_files.extend(glob.glob(ext))
    audio_files.extend(glob.glob(ext.upper()))

# –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
audio_files = list(set(audio_files))

if not audio_files:
    print("–ê—É–¥–∏–æ—Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
    exit()

print(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(audio_files)}")
for file in audio_files:
    file_size = os.path.getsize(file) / (1024 * 1024)
    print(f"  - {os.path.basename(file)} ({file_size:.1f} MB)")

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
print(f"\nüîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper {selected_model}...")
model_load_start = time.time()
model = whisper.load_model(selected_model, device=device)
model_load_time = time.time() - model_load_start
print(f"‚úÖ –ú–æ–¥–µ–ª—å '{selected_model}' –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {model_load_time:.1f} —Å–µ–∫")

def split_audio_with_overlap(file_path, segment_length_ms=70000, overlap_ms=10000):  # 1:10 –º–∏–Ω—É—Ç —Å –∑–∞—Ö–ª–µ—Å—Ç–æ–º 10 —Å–µ–∫
    """–†–∞–∑–±–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã —Å –∑–∞—Ö–ª–µ—Å—Ç–æ–º"""
    print(f"‚úÇÔ∏è  –†–∞–∑–±–∏–≤–∞–µ–º –∞—É–¥–∏–æ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã {segment_length_ms/60000:.1f} –º–∏–Ω —Å –∑–∞—Ö–ª–µ—Å—Ç–æ–º {overlap_ms/1000} —Å–µ–∫...")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª
        audio = AudioSegment.from_file(file_path)
        duration_ms = len(audio)
        duration_sec = duration_ms / 1000
        print(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª–∞: {duration_sec/60:.1f} –º–∏–Ω—É—Ç")
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        base_name = os.path.splitext(file_path)[0]
        segments_dir = f"{base_name}_segments"
        os.makedirs(segments_dir, exist_ok=True)
        
        segments_info = []
        step_ms = segment_length_ms - overlap_ms  # –®–∞–≥ –º–µ–∂–¥—É –Ω–∞—á–∞–ª–∞–º–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        
        i = 0
        start_ms = 0
        
        while start_ms < duration_ms:
            end_ms = min(start_ms + segment_length_ms, duration_ms)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç
            chunk = audio[start_ms:end_ms]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç
            chunk_name = f"{base_name}_part{i+1:03d}.wav"
            chunk_path = os.path.join(segments_dir, chunk_name)
            chunk.export(chunk_path, format="wav")
            
            segments_info.append({
                'path': chunk_path,
                'start': start_ms / 1000,
                'end': end_ms / 1000,
                'index': i + 1
            })
            
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Å–µ–≥–º–µ–Ω—Ç—É
            start_ms += step_ms
            i += 1
            
            # –ï—Å–ª–∏ –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º
            if duration_ms - start_ms < overlap_ms and i > 0:
                break
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –∑–∞—Ö–ª–µ—Å—Ç–æ–º: {len(segments_info)}")
        
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ö
        for seg in segments_info:
            start_min = int(seg['start'] // 60)
            start_sec = int(seg['start'] % 60)
            end_min = int(seg['end'] // 60)
            end_sec = int(seg['end'] % 60)
            print(f"   {start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d}")
            
        return segments_info, duration_sec
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–∏–≤–∫–µ –∞—É–¥–∏–æ: {e}")
        return [], 0

def transcribe_segment(segment_path, segment_index, total_segments):
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥–∏–æ"""
    print(f"   üéß –°–µ–≥–º–µ–Ω—Ç {segment_index}/{total_segments}...")
    
    try:
        result = model.transcribe(
            segment_path,
            language="ru",
            fp16=(device == "cuda"),
            temperature=0.0,
            best_of=3,
            beam_size=3,
            no_speech_threshold=0.6,
            condition_on_previous_text=use_context  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        )
        
        text = result["text"].strip()
        return text
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Å–µ–≥–º–µ–Ω—Ç–∞ {segment_index}: {e}")
        return ""

def create_ai_prompt(filename, total_duration, total_segments, lecture_text):
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è AI —Å —Ç–µ–∫—Å—Ç–æ–º –ª–µ–∫—Ü–∏–∏"""
    
    prompt = f"""–ü–†–û–ú–ü–¢ –î–õ–Ø –ö–û–ù–°–ü–ï–ö–¢–ò–†–û–í–ê–ù–ò–Ø –õ–ï–ö–¶–ò–ò

–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –õ–ï–ö–¶–ò–ò:
- –§–∞–π–ª: {filename}
- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_duration/60:.1f} –º–∏–Ω—É—Ç
- –°–µ–≥–º–µ–Ω—Ç–æ–≤: {total_segments}

–ó–ê–î–ê–ù–ò–ï:
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ª–µ–∫—Ü–∏–∏ –∏ —Å–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç. –¢–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç—Å–∫–æ–π –ª–µ–∫—Ü–∏–∏.
–¢–∞–∫ –∫–∞–∫ —Ç–µ–∫—Å—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ç–æ –≤ –Ω–µ–º –µ—Å—Ç—å –∏—Å–∫–∞–∂–µ–Ω–∏—è —Å–ª–æ–≤.
–ù—É–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å —ç—Ç—É –ª–µ–∫—Ü–∏—é –≤ —Ç–æ–º –ø–æ—Ä—è–¥–∫–µ –≤ –∫–æ—Ç–æ—Ä–æ–º –∏–¥–µ—Ç –ª–µ–∫—Ü–∏—è.
–≤—Å–µ —ç—Ç–æ –æ—Ñ–æ—Ä–º–∏—Ç—å –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è obsidian.


–¢–ï–ö–°–¢ –õ–ï–ö–¶–ò–ò –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
{lecture_text}

–ö–û–ù–ï–¶ –¢–ï–ö–°–¢–ê –õ–ï–ö–¶–ò–ò
"""
    return prompt

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
successful_files = 0

for audio_file in audio_files:
    filename = os.path.basename(audio_file)
    file_size = os.path.getsize(audio_file) / (1024 * 1024)
    
    print(f"\nüéØ –û–±—Ä–∞–±–æ—Ç–∫–∞: {filename} ({file_size:.1f} MB)")
    print("=" * 50)
    
    start_time = time.time()
    
    # 1. –†–∞–∑–±–∏–≤–∞–µ–º –∞—É–¥–∏–æ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã –° –ó–ê–•–õ–ï–°–¢–û–ú
    segments_info, total_duration = split_audio_with_overlap(audio_file)
    
    if not segments_info:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–±–∏—Ç—å –∞—É–¥–∏–æ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã")
        continue
    
    # 2. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç
    all_transcriptions = []
    full_lecture_text = ""
    
    for i, segment in enumerate(segments_info):
        start_min = int(segment['start'] // 60)
        start_sec = int(segment['start'] % 60)
        end_min = int(segment['end'] // 60)
        end_sec = int(segment['end'] % 60)
        
        progress = f"[{i+1}/{len(segments_info)}]"
        
        print(f"   {progress} {start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d}")
        
        segment_text = transcribe_segment(segment['path'], i+1, len(segments_info))
        
        if segment_text:
            segment_header = f"\n--- –°–ï–ì–ú–ï–ù–¢ {i+1} ({start_min:02d}:{start_sec:02d}-{end_min:02d}:{end_sec:02d}) ---\n"
            formatted_segment = segment_header + segment_text + "\n"
            all_transcriptions.append(formatted_segment)
            full_lecture_text += segment_text + " "
        
        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ GPU –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    # 3. –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è AI
    base_name = os.path.splitext(audio_file)[0]
    output_file = f"{base_name}_–¥–ª—è_–∫–æ–Ω—Å–ø–µ–∫—Ç–∞.md"
    
    ai_prompt = create_ai_prompt(filename, total_duration, len(segments_info), full_lecture_text)
    
    # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –≤ —Ñ–∞–π–ª
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(ai_prompt)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
        transcript_file = f"{base_name}_–ø–æ–ª–Ω–∞—è_—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è.md"
        with open(transcript_file, "w", encoding="utf-8") as f:
            f.write("# –ü–û–õ–ù–ê–Ø –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø –õ–ï–ö–¶–ò–ò\n\n")
            f.writelines(all_transcriptions)
        
        processing_time = time.time() - start_time
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_text_length = len(full_lecture_text)
        
        print(f"\n‚úÖ –§–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {processing_time:.1f} —Å–µ–∫")
        print(f"üìÑ –°–æ–∑–¥–∞–Ω—ã —Ñ–∞–π–ª—ã:")
        print(f"   - {output_file} (–ø—Ä–æ–º–ø—Ç –¥–ª—è AI)")
        print(f"   - {transcript_file} (–ø–æ–ª–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è)")
        print(f"üìù –û–±—â–∏–π —Ç–µ–∫—Å—Ç: {total_text_length} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –Ω–∞ –º–∏–Ω—É—Ç—É –∞—É–¥–∏–æ: {processing_time/(total_duration/60):.1f} —Å–µ–∫/–º–∏–Ω")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥
        print(f"\nüéØ –°–õ–ï–î–£–Æ–©–ò–ô –®–ê–ì:")
        print(f"   –°–∫–æ–ø–∏—Ä—É–π —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ '{output_file}'")
        print(f"   –ò –æ—Ç–ø—Ä–∞–≤—å –º–Ω–µ - —è —Å–æ–∑–¥–∞–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç!")
        
        successful_files += 1
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        import shutil
        segments_dir = f"{base_name}_segments"
        if os.path.exists(segments_dir):
            shutil.rmtree(segments_dir)
            print("üßπ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —É–¥–∞–ª–µ–Ω—ã")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")

# –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
total_time = time.time() - total_start_time
print("\n" + "=" * 70)
print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
print("=" * 70)
print(f"üïí –û–±—â–µ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {total_time:.1f} —Å–µ–∫ ({total_time/60:.1f} –º–∏–Ω)")
print(f"‚è±Ô∏è  –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {model_load_time:.1f} —Å–µ–∫")
print(f"ü§ñ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: {selected_model}")
print(f"üîÑ –†–µ–∂–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {'–í–ö–õ' if use_context else '–í–´–ö–õ'}")
print(f"üìÅ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {successful_files}/{len(audio_files)}")

if successful_files > 0:
    print(f"\nüéØ –†–ï–ñ–ò–ú –û–ë–†–ê–ë–û–¢–ö–ò:")
    print(f"   ‚Ä¢ –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ 1:10 –º–∏–Ω—É—Ç —Å –∑–∞—Ö–ª–µ—Å—Ç–æ–º 10 —Å–µ–∫")
    print(f"   ‚Ä¢ –°–µ–≥–º–µ–Ω—Ç—ã: 00:00-1:10, 01:00-2:10, 02:00-3:10 –∏ —Ç.–¥.")
    print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å: Whisper {selected_model}")
    print(f"   ‚Ä¢ –ö–æ–Ω—Ç–µ–∫—Å—Ç: {'–í–ö–õ' if use_context else '–í–´–ö–õ'}")
    print(f"   ‚Ä¢ –í—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    print(f"     - _–¥–ª—è_–∫–æ–Ω—Å–ø–µ–∫—Ç–∞.md - –ø—Ä–æ–º–ø—Ç –¥–ª—è AI")
    print(f"     - _–ø–æ–ª–Ω–∞—è_—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è.md - —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç")

print("\nüí° –ò–ù–°–¢–†–£–ö–¶–ò–Ø:")
print("   1. –û—Ç–∫—Ä–æ–π —Ñ–∞–π–ª —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º '_–¥–ª—è_–∫–æ–Ω—Å–ø–µ–∫—Ç–∞.md'")
print("   2. –°–∫–æ–ø–∏—Ä—É–π –í–ï–°–¨ –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ")
print("   3. –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç")
print("   4. –Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –ª–µ–∫—Ü–∏—é –∏ —Å–æ–∑–¥–∞–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç!")

print("=" * 70)
print("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ñ–¥—É –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ–Ω—Å–ø–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è! üéì")
input("–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")